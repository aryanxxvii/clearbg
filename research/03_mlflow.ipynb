{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from clearbg.model.u2net import U2NET  # Update with your model import\n",
    "from clearbg.utils.utils import SalObjDataset, RescaleT, ToTensorLab  # Update with your data loader imports\n",
    "from clearbg.utils.common import read_yaml, save_json  # Update with your utility imports\n",
    "import numpy as np\n",
    "\n",
    "# Set up the MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://dagshub.com/entbappy/Chest-Disease-Classification-MLflow-DVC.mlflow\")\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    model_path: Path\n",
    "    test_data_dir: Path\n",
    "    prediction_dir: Path\n",
    "    params: dict\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=\"config.yaml\", params_filepath=\"params.yaml\"):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "    \n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        return EvaluationConfig(\n",
    "            model_path=Path(self.config.training.root_dir) / \"saved_models\" / \"u2net\" / \"u2net.pth\",\n",
    "            test_data_dir=Path(self.config.data_ingestion.root_dir) / \"test_data\" / \"test_images\",\n",
    "            prediction_dir=Path(self.config.data_ingestion.root_dir) / \"test_data\" / \"u2net_results\",\n",
    "            params=self.params\n",
    "        )\n",
    "\n",
    "def load_model(model_path: Path) -> torch.nn.Module:\n",
    "    model = U2NET(3, 1)  # Ensure this matches your model's input/output\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model: torch.nn.Module, dataloader: DataLoader) -> float:\n",
    "    total_loss = 0\n",
    "    num_samples = len(dataloader)\n",
    "    \n",
    "    # Assuming you have a loss function defined elsewhere\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data['image'], data['label']\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / num_samples\n",
    "    return average_loss\n",
    "\n",
    "def save_output(predictions, img_name_list, prediction_dir):\n",
    "    if not os.path.exists(prediction_dir):\n",
    "        os.makedirs(prediction_dir, exist_ok=True)\n",
    "    \n",
    "    for img_name, pred in zip(img_name_list, predictions):\n",
    "        pred_np = pred.squeeze().cpu().numpy()\n",
    "        im = Image.fromarray((pred_np * 255).astype(np.uint8)).convert('RGB')\n",
    "        img_name_only = os.path.basename(img_name).split('.')[0]\n",
    "        im.save(os.path.join(prediction_dir, f\"{img_name_only}.png\"))\n",
    "\n",
    "def main():\n",
    "    config_manager = ConfigurationManager()\n",
    "    eval_config = config_manager.get_evaluation_config()\n",
    "    \n",
    "    # Set up the data loader\n",
    "    image_list = glob.glob(os.path.join(eval_config.test_data_dir, '*'))\n",
    "    \n",
    "    test_dataset = SalObjDataset(\n",
    "        img_name_list=image_list,\n",
    "        lbl_name_list=[],  # Assuming no labels for test set\n",
    "        transform=transforms.Compose([\n",
    "            RescaleT(320),\n",
    "            ToTensorLab(flag=0)\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Load model and evaluate\n",
    "    model = load_model(eval_config.model_path)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(eval_config.params)\n",
    "\n",
    "        average_loss = evaluate_model(model, test_dataloader)\n",
    "        mlflow.log_metrics({\"average_loss\": average_loss})\n",
    "\n",
    "        # Save outputs if needed\n",
    "        predictions = []\n",
    "        for data in test_dataloader:\n",
    "            inputs = data['image']\n",
    "            with torch.no_grad():\n",
    "                output = model(inputs)\n",
    "                predictions.append(output)\n",
    "\n",
    "        save_output(predictions, image_list, eval_config.prediction_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopsproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
